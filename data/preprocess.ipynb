{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = []\n",
    "annotated = []\n",
    "words_queue = []\n",
    "files = set()\n",
    "with zipfile.ZipFile('MACCROBAT2018.zip', 'r') as z:\n",
    "    for filename in z.namelist():\n",
    "        files.add(filename.split(\".\")[0])\n",
    "\n",
    "    for filename in files:\n",
    "        with z.open(filename + \".txt\") as file:\n",
    "            for line in file:\n",
    "                sentence = line.decode('utf-8').strip()\n",
    "                if sentence:\n",
    "                    input_text.append(sentence)\n",
    "\n",
    "with zipfile.ZipFile('MACCROBAT2020.zip', 'r') as z:\n",
    "    for filename in z.namelist():\n",
    "        files.add(filename.split(\".\")[0])\n",
    "\n",
    "    for filename in files:\n",
    "        with z.open(filename + \".txt\") as file:\n",
    "            for line in file:\n",
    "                sentence = line.decode('utf-8').strip()\n",
    "                if sentence:\n",
    "                    input_text.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def generate_detailed_tags(sentences):\n",
    "    detailed_tags = []\n",
    "\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        if index % 1000 == 0:\n",
    "            print(index)\n",
    "\n",
    "        # Process the sentence with spaCy\n",
    "        doc = nlp(sentence)\n",
    "\n",
    "        # Initialize BIO tags as \"O\" for all tokens\n",
    "        bio_tags = [\"O\"] * len(doc)\n",
    "\n",
    "        # Assign B- and I- tags based on entities\n",
    "        for ent in doc.ents:\n",
    "            start = ent.start\n",
    "            end = ent.end\n",
    "\n",
    "            # First token in the entity gets B- prefix\n",
    "            bio_tags[start] = f\"B-{ent.label_}\"\n",
    "\n",
    "            # Subsequent tokens in the entity get I- prefix\n",
    "            for i in range(start + 1, end):\n",
    "                bio_tags[i] = f\"I-{ent.label_}\"\n",
    "\n",
    "        # Collect tokens, POS tags, and BIO tags\n",
    "        tokens = [token.text for token in doc]\n",
    "        pos_tags = [token.pos_ for token in doc]\n",
    "\n",
    "        # Add to the output\n",
    "        detailed_tags.append({\n",
    "            \"sentence\": sentence,\n",
    "            \"tokens\": tokens,\n",
    "            \"pos_tags\": pos_tags,\n",
    "            \"ner_tags\": bio_tags\n",
    "        })\n",
    "\n",
    "    return detailed_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n"
     ]
    }
   ],
   "source": [
    "# Generate detailed tags\n",
    "detailed_tags_output = generate_detailed_tags(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: A 46-year-old Caucasian woman with type 2 diabetes mellitus and bipolar disorder presented to our emergency department with vague abdominal symptoms and vomiting.\n",
      "Tokens: ['A', '46', '-', 'year', '-', 'old', 'Caucasian', 'woman', 'with', 'type', '2', 'diabetes', 'mellitus', 'and', 'bipolar', 'disorder', 'presented', 'to', 'our', 'emergency', 'department', 'with', 'vague', 'abdominal', 'symptoms', 'and', 'vomiting', '.']\n",
      "POS Tags: ['DET', 'NUM', 'PUNCT', 'NOUN', 'PUNCT', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'NUM', 'NOUN', 'ADJ', 'CCONJ', 'ADJ', 'NOUN', 'VERB', 'ADP', 'PRON', 'NOUN', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'CCONJ', 'NOUN', 'PUNCT']\n",
      "NER Tags: ['O', 'B-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'I-DATE', 'B-NORP', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Her pertinent history includes left below knee amputation and right toes amputation for complications secondary to diabetic neuropathy.\n",
      "Tokens: ['Her', 'pertinent', 'history', 'includes', 'left', 'below', 'knee', 'amputation', 'and', 'right', 'toes', 'amputation', 'for', 'complications', 'secondary', 'to', 'diabetic', 'neuropathy', '.']\n",
      "POS Tags: ['PRON', 'ADJ', 'NOUN', 'VERB', 'VERB', 'ADP', 'NOUN', 'NOUN', 'CCONJ', 'ADJ', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'PART', 'VERB', 'ADJ', 'PUNCT']\n",
      "NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: At the time of admission, she was undergoing care for an infected diabetic ulcer of her right foot.\n",
      "Tokens: ['At', 'the', 'time', 'of', 'admission', ',', 'she', 'was', 'undergoing', 'care', 'for', 'an', 'infected', 'diabetic', 'ulcer', 'of', 'her', 'right', 'foot', '.']\n",
      "POS Tags: ['ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'PUNCT', 'PRON', 'AUX', 'VERB', 'NOUN', 'ADP', 'DET', 'VERB', 'ADJ', 'NOUN', 'ADP', 'PRON', 'ADJ', 'NOUN', 'PUNCT']\n",
      "NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "Sentence: Of note, she did not have a history of CAPD or a history of renal disease: creatinine 1.23 mg/dL, blood urea nitrogen (BUN) 16 mg/dL.\n",
      "Tokens: ['Of', 'note', ',', 'she', 'did', 'not', 'have', 'a', 'history', 'of', 'CAPD', 'or', 'a', 'history', 'of', 'renal', 'disease', ':', 'creatinine', '1.23', 'mg', '/', 'dL', ',', 'blood', 'urea', 'nitrogen', '(', 'BUN', ')', '16', 'mg', '/', 'dL.']\n",
      "POS Tags: ['ADP', 'VERB', 'PUNCT', 'PRON', 'AUX', 'PART', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'CCONJ', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'PUNCT', 'NOUN', 'NUM', 'PROPN', 'SYM', 'PROPN', 'PUNCT', 'NOUN', 'NOUN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'NUM', 'ADP', 'SYM', 'PROPN']\n",
      "NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'B-QUANTITY', 'I-QUANTITY', 'I-QUANTITY', 'I-QUANTITY']\n",
      "\n",
      "Sentence: Her blood glucose levels were poorly controlled via subcutaneous insulin injection; she reported a range of 400 to 500 mg/dL at home (due to poor drug compliance).\n",
      "Tokens: ['Her', 'blood', 'glucose', 'levels', 'were', 'poorly', 'controlled', 'via', 'subcutaneous', 'insulin', 'injection', ';', 'she', 'reported', 'a', 'range', 'of', '400', 'to', '500', 'mg', '/', 'dL', 'at', 'home', '(', 'due', 'to', 'poor', 'drug', 'compliance', ')', '.']\n",
      "POS Tags: ['PRON', 'NOUN', 'NOUN', 'NOUN', 'AUX', 'ADV', 'VERB', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'NUM', 'PART', 'NUM', 'NOUN', 'SYM', 'NUM', 'ADP', 'NOUN', 'PUNCT', 'ADJ', 'ADP', 'ADJ', 'NOUN', 'NOUN', 'PUNCT', 'PUNCT']\n",
      "NER Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CARDINAL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print output\n",
    "for entry in detailed_tags_output[:5]:\n",
    "    print(f\"Sentence: {entry['sentence']}\")\n",
    "    print(f\"Tokens: {entry['tokens']}\")\n",
    "    print(f\"POS Tags: {entry['pos_tags']}\")\n",
    "    print(f\"NER Tags: {entry['ner_tags']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save to a JSON file\n",
    "with open(\"tagged_medical_sentences.json\", \"w\") as f:\n",
    "    json.dump(detailed_tags_output, f, indent=4)\n",
    "\n",
    "print(\"Output saved to 'tagged_medical_sentences.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
